{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "2122c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba0f42",
   "metadata": {},
   "source": [
    "Загрузите данные. Используйте датасет с ирисами. Его можно загрузить непосредственно из библиотеки Sklearn. В данных оставьте только 2 класса: Iris Versicolor, Iris Virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8cdf5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасет iris, определяем признаки и целевую переменную\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "bb239456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "566a8767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оставляем 2 класса: 0 - 'versicolor', 1 - 'virginica'\n",
    "X = iris.data[iris.target != 0]\n",
    "y = iris.target[iris.target != 0] - 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c0d82153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2. , 3. , 2.2,\n",
       "       2.9, 2.9, 3.1, 3. , 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3. ,\n",
       "       2.8, 3. , 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3. , 3.4, 3.1, 2.3, 3. ,\n",
       "       2.5, 2.6, 3. , 2.6, 2.3, 2.7, 3. , 2.9, 2.9, 2.5, 2.8, 3.3, 2.7,\n",
       "       3. , 2.9, 3. , 3. , 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3. , 2.5, 2.8,\n",
       "       3.2, 3. , 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3. ,\n",
       "       2.8, 3. , 2.8, 3.8, 2.8, 2.8, 2.6, 3. , 3.4, 3.1, 3. , 3.1, 3.1,\n",
       "       3.1, 2.7, 3.2, 3.3, 3. , 2.5, 3. , 3.4, 3. ])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62f401",
   "metadata": {},
   "source": [
    "Самостоятельно реализуйте логистическую регрессию, без использования метода LogisticRegression из библиотеки. Реализуйте метод градиентного спуска. Обучите логистическую регрессию этим методом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "049d7f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка точности модели: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Для начала реализуем встроенный метод логистической регрессии\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучим модель встроенным модулем\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# И оценим качество модели\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Оценка точности модели:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "d4ec7a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.35674468, -0.73750193,  2.83425127,  2.19287166]]),\n",
       " array([-13.16274078]))"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получим коэффициенты\n",
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ac6bcafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Реальные значения  Предсказанные значения\n",
      "0                   1                       1\n",
      "1                   1                       1\n",
      "2                   1                       1\n",
      "3                   0                       0\n",
      "4                   0                       0\n",
      "5                   0                       0\n",
      "6                   0                       0\n",
      "7                   1                       1\n",
      "8                   0                       0\n",
      "9                   0                       0\n",
      "10                  0                       0\n",
      "11                  0                       0\n",
      "12                  1                       1\n",
      "13                  0                       1\n",
      "14                  1                       1\n",
      "15                  0                       0\n",
      "16                  1                       1\n",
      "17                  1                       1\n",
      "18                  0                       0\n",
      "19                  0                       0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "data_results = pd.DataFrame({\n",
    "    'Реальные значения': y_test,\n",
    "    'Предсказанные значения': y_pred\n",
    "})\n",
    "print(data_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d4954fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация 0\n",
      "Logloss: 0.6927\n",
      "Accuracy: 0.9000\n",
      "--------------------------------------------------------\n",
      "Итерация 100\n",
      "Logloss: 0.6544\n",
      "Accuracy: 0.9000\n",
      "--------------------------------------------------------\n",
      "Итерация 200\n",
      "Logloss: 0.6210\n",
      "Accuracy: 0.9000\n",
      "--------------------------------------------------------\n",
      "Итерация 300\n",
      "Logloss: 0.5917\n",
      "Accuracy: 0.9100\n",
      "--------------------------------------------------------\n",
      "Итерация 400\n",
      "Logloss: 0.5659\n",
      "Accuracy: 0.9100\n",
      "--------------------------------------------------------\n",
      "Итерация 500\n",
      "Logloss: 0.5432\n",
      "Accuracy: 0.9100\n",
      "--------------------------------------------------------\n",
      "Итерация 600\n",
      "Logloss: 0.5230\n",
      "Accuracy: 0.9100\n",
      "--------------------------------------------------------\n",
      "Итерация 700\n",
      "Logloss: 0.5050\n",
      "Accuracy: 0.9100\n",
      "--------------------------------------------------------\n",
      "Итерация 800\n",
      "Logloss: 0.4887\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 900\n",
      "Logloss: 0.4741\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1000\n",
      "Logloss: 0.4608\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1100\n",
      "Logloss: 0.4487\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1200\n",
      "Logloss: 0.4376\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1300\n",
      "Logloss: 0.4274\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1400\n",
      "Logloss: 0.4180\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1500\n",
      "Logloss: 0.4092\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1600\n",
      "Logloss: 0.4011\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1700\n",
      "Logloss: 0.3935\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1800\n",
      "Logloss: 0.3864\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 1900\n",
      "Logloss: 0.3798\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2000\n",
      "Logloss: 0.3735\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2100\n",
      "Logloss: 0.3675\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2200\n",
      "Logloss: 0.3619\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2300\n",
      "Logloss: 0.3566\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2400\n",
      "Logloss: 0.3516\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2500\n",
      "Logloss: 0.3468\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2600\n",
      "Logloss: 0.3422\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2700\n",
      "Logloss: 0.3378\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2800\n",
      "Logloss: 0.3337\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 2900\n",
      "Logloss: 0.3297\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3000\n",
      "Logloss: 0.3258\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3100\n",
      "Logloss: 0.3221\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3200\n",
      "Logloss: 0.3186\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3300\n",
      "Logloss: 0.3152\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3400\n",
      "Logloss: 0.3119\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3500\n",
      "Logloss: 0.3087\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3600\n",
      "Logloss: 0.3056\n",
      "Accuracy: 0.9300\n",
      "--------------------------------------------------------\n",
      "Итерация 3700\n",
      "Logloss: 0.3026\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 3800\n",
      "Logloss: 0.2998\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 3900\n",
      "Logloss: 0.2970\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4000\n",
      "Logloss: 0.2943\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4100\n",
      "Logloss: 0.2917\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4200\n",
      "Logloss: 0.2891\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4300\n",
      "Logloss: 0.2867\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4400\n",
      "Logloss: 0.2843\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4500\n",
      "Logloss: 0.2819\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4600\n",
      "Logloss: 0.2797\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4700\n",
      "Logloss: 0.2775\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4800\n",
      "Logloss: 0.2753\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 4900\n",
      "Logloss: 0.2732\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 5000\n",
      "Logloss: 0.2711\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 5100\n",
      "Logloss: 0.2691\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 5200\n",
      "Logloss: 0.2672\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 5300\n",
      "Logloss: 0.2653\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 5400\n",
      "Logloss: 0.2634\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 5500\n",
      "Logloss: 0.2616\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 5600\n",
      "Logloss: 0.2598\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 5700\n",
      "Logloss: 0.2581\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 5800\n",
      "Logloss: 0.2564\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 5900\n",
      "Logloss: 0.2547\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6000\n",
      "Logloss: 0.2531\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6100\n",
      "Logloss: 0.2515\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6200\n",
      "Logloss: 0.2499\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6300\n",
      "Logloss: 0.2483\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6400\n",
      "Logloss: 0.2468\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6500\n",
      "Logloss: 0.2453\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6600\n",
      "Logloss: 0.2439\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6700\n",
      "Logloss: 0.2425\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6800\n",
      "Logloss: 0.2411\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 6900\n",
      "Logloss: 0.2397\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7000\n",
      "Logloss: 0.2383\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7100\n",
      "Logloss: 0.2370\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7200\n",
      "Logloss: 0.2357\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7300\n",
      "Logloss: 0.2344\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7400\n",
      "Logloss: 0.2332\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7500\n",
      "Logloss: 0.2319\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7600\n",
      "Logloss: 0.2307\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7700\n",
      "Logloss: 0.2295\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7800\n",
      "Logloss: 0.2283\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 7900\n",
      "Logloss: 0.2271\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8000\n",
      "Logloss: 0.2260\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8100\n",
      "Logloss: 0.2249\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8200\n",
      "Logloss: 0.2238\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8300\n",
      "Logloss: 0.2227\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8400\n",
      "Logloss: 0.2216\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8500\n",
      "Logloss: 0.2205\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8600\n",
      "Logloss: 0.2195\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8700\n",
      "Logloss: 0.2185\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 8800\n",
      "Logloss: 0.2175\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Остановились на итерации 8846\n"
     ]
    }
   ],
   "source": [
    "# Теперь самостоятельно реализуем метод логистической регрессии методом градиентного спуска\n",
    "\n",
    "# Масштабируем признаки \n",
    "scaler = StandardScaler()\n",
    "X_scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "# Добавляем столбец единиц для свободного веса\n",
    "X = np.c_[np.ones(len(X_scaled_features)), X_scaled_features]\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Функция сигмоиды\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Функция для вычисления логарифмической функции потерь\n",
    "def logloss(y, y_proba):\n",
    "    return -np.mean(y * np.log(y_proba + 1e-30) + (1 - y) * np.log(1 - y_proba + 1e-30))\n",
    "\n",
    "# Градиентный спуск\n",
    "def gr_logloss(X, W, y):\n",
    "    y_proba = sigmoid(X @ W)\n",
    "    grad = X.T @ (y_proba - y) / len(y)\n",
    "    return grad\n",
    "\n",
    "# Параметры обучения \n",
    "# learning_rate: скорость обучения, epochs: количество итераций, beta: скорость сглаживания\n",
    "eps = 0.0001\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epochs = 10000\n",
    "\n",
    "# Инициализация весов\n",
    "W = np.zeros(X.shape[1])\n",
    "\n",
    "for i in range(epochs):\n",
    "    cur_W = W.copy()  # текущие веса\n",
    "    \n",
    "    # Градиент по текущим весам\n",
    "    grad = gr_logloss(X, cur_W, y)\n",
    "    \n",
    "    # Обновляем веса\n",
    "    W_next = cur_W - learning_rate * grad\n",
    "    \n",
    "    # Проверка условия остановки\n",
    "    if np.linalg.norm(W - W_next) <= eps:\n",
    "        print(f\"Остановились на итерации {i}\")\n",
    "        break\n",
    "    \n",
    "    # Обновляем веса для следующей итерации\n",
    "    W = W_next\n",
    "    \n",
    "    # Каждые 100 итераций выводим информацию\n",
    "    if i % 100 == 0:\n",
    "        y_proba = sigmoid(X @ W)\n",
    "        y_class = (y_proba >= 0.5).astype(int)\n",
    "        accuracy = (y_class == y).mean()\n",
    "        print(f\"Итерация {i}\")\n",
    "        print(f\"Logloss: {logloss(y, y_proba):.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "8df19b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Реальные значения  Предсказанные значения  Предсказанные вероятности\n",
      "0                   0                       0                   0.298119\n",
      "1                   0                       0                   0.256167\n",
      "2                   0                       0                   0.424590\n",
      "3                   0                       0                   0.073151\n",
      "4                   0                       0                   0.307064\n",
      "..                ...                     ...                        ...\n",
      "95                  1                       1                   0.921544\n",
      "96                  1                       1                   0.714147\n",
      "97                  1                       1                   0.813697\n",
      "98                  1                       1                   0.921004\n",
      "99                  1                       1                   0.620383\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_results = pd.DataFrame({\n",
    "    'Реальные значения': y,\n",
    "    'Предсказанные значения': y_class,\n",
    "    'Предсказанные вероятности': y_proba\n",
    "})\n",
    "print(data_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "1670d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальные веса: [ 0.02372129  0.26548554 -0.06459134  1.11430539  1.28339433]\n",
      "Итераций: 8846\n",
      "Оценка точности модели методом градиентного спуска: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"Финальные веса:\", W)\n",
    "i_grad = i\n",
    "print(\"Итераций:\", i_grad)\n",
    "accuracy_grad = accuracy\n",
    "print(\"Оценка точности модели методом градиентного спуска:\", accuracy_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08234d7e",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию этим методом скользящего среднего (Root Mean Square Propagation, RMSProp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "d34e2913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация 0\n",
      "Logloss: 0.6894\n",
      "Accuracy: 0.8000\n",
      "--------------------------------------------------------\n",
      "Итерация 100\n",
      "Logloss: 0.5800\n",
      "Accuracy: 0.8000\n",
      "--------------------------------------------------------\n",
      "Итерация 200\n",
      "Logloss: 0.5045\n",
      "Accuracy: 0.8000\n",
      "--------------------------------------------------------\n",
      "Итерация 300\n",
      "Logloss: 0.4494\n",
      "Accuracy: 0.8100\n",
      "--------------------------------------------------------\n",
      "Итерация 400\n",
      "Logloss: 0.4057\n",
      "Accuracy: 0.8400\n",
      "--------------------------------------------------------\n",
      "Итерация 500\n",
      "Logloss: 0.3692\n",
      "Accuracy: 0.8900\n",
      "--------------------------------------------------------\n",
      "Итерация 600\n",
      "Logloss: 0.3387\n",
      "Accuracy: 0.9100\n",
      "--------------------------------------------------------\n",
      "Итерация 700\n",
      "Logloss: 0.3123\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 800\n",
      "Logloss: 0.2887\n",
      "Accuracy: 0.9400\n",
      "--------------------------------------------------------\n",
      "Итерация 900\n",
      "Logloss: 0.2675\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 1000\n",
      "Logloss: 0.2484\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 1100\n",
      "Logloss: 0.2311\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 1200\n",
      "Logloss: 0.2155\n",
      "Accuracy: 0.9500\n",
      "--------------------------------------------------------\n",
      "Итерация 1300\n",
      "Logloss: 0.2014\n",
      "Accuracy: 0.9600\n",
      "--------------------------------------------------------\n",
      "Итерация 1400\n",
      "Logloss: 0.1887\n",
      "Accuracy: 0.9600\n",
      "--------------------------------------------------------\n",
      "Итерация 1500\n",
      "Logloss: 0.1773\n",
      "Accuracy: 0.9600\n",
      "--------------------------------------------------------\n",
      "Итерация 1600\n",
      "Logloss: 0.1669\n",
      "Accuracy: 0.9600\n",
      "--------------------------------------------------------\n",
      "Итерация 1700\n",
      "Logloss: 0.1576\n",
      "Accuracy: 0.9600\n",
      "--------------------------------------------------------\n",
      "Итерация 1800\n",
      "Logloss: 0.1492\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 1900\n",
      "Logloss: 0.1415\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2000\n",
      "Logloss: 0.1346\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2100\n",
      "Logloss: 0.1283\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2200\n",
      "Logloss: 0.1227\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2300\n",
      "Logloss: 0.1175\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2400\n",
      "Logloss: 0.1128\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 2500\n",
      "Logloss: 0.1086\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 2600\n",
      "Logloss: 0.1047\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2700\n",
      "Logloss: 0.1011\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2800\n",
      "Logloss: 0.0979\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 2900\n",
      "Logloss: 0.0949\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3000\n",
      "Logloss: 0.0922\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3100\n",
      "Logloss: 0.0898\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3200\n",
      "Logloss: 0.0875\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3300\n",
      "Logloss: 0.0854\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3400\n",
      "Logloss: 0.0835\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3500\n",
      "Logloss: 0.0818\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3600\n",
      "Logloss: 0.0801\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3700\n",
      "Logloss: 0.0787\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3800\n",
      "Logloss: 0.0773\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 3900\n",
      "Logloss: 0.0760\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4000\n",
      "Logloss: 0.0749\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4100\n",
      "Logloss: 0.0738\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4200\n",
      "Logloss: 0.0728\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4300\n",
      "Logloss: 0.0719\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4400\n",
      "Logloss: 0.0710\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4500\n",
      "Logloss: 0.0702\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4600\n",
      "Logloss: 0.0695\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4700\n",
      "Logloss: 0.0688\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4800\n",
      "Logloss: 0.0682\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 4900\n",
      "Logloss: 0.0676\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5000\n",
      "Logloss: 0.0670\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5100\n",
      "Logloss: 0.0665\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5200\n",
      "Logloss: 0.0660\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5300\n",
      "Logloss: 0.0656\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5400\n",
      "Logloss: 0.0652\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5500\n",
      "Logloss: 0.0648\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5600\n",
      "Logloss: 0.0645\n",
      "Accuracy: 0.9700\n",
      "--------------------------------------------------------\n",
      "Итерация 5700\n",
      "Logloss: 0.0641\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Остановились на итерации 5763\n"
     ]
    }
   ],
   "source": [
    "# Реализуем метод логистической регрессии методом скользящего среднего\n",
    "\n",
    "eps = 0.001\n",
    "W = np.zeros(X.shape[1])\n",
    "# Инициализация переменной для скользящего среднего квадрата градиентов\n",
    "v = np.zeros_like(W)\n",
    "\n",
    "for i in range(epochs):\n",
    "    cur_W = W.copy()  # текущие веса\n",
    "    \n",
    "    # Градиент по текущим весам\n",
    "    grad = gr_logloss(X, cur_W, y)\n",
    "    \n",
    "    # Обновляем v\n",
    "    v = beta1 * v + (1 - beta1) * (grad ** 2)\n",
    "    \n",
    "    # Обновляем веса с учетом RMSProp\n",
    "    W_next = cur_W - (learning_rate / (np.sqrt(v) + eps)) * grad\n",
    "    \n",
    "    # Проверка условия остановки\n",
    "    if np.linalg.norm(W - W_next) <= eps:\n",
    "        print(f\"Остановились на итерации {i}\")\n",
    "        break       \n",
    "    \n",
    "    # Обновляем веса для следующей итерации\n",
    "    W = W_next\n",
    "\n",
    "    # Каждые 100 итераций выводим информацию\n",
    "    if i % 100 == 0:\n",
    "        y_proba = sigmoid(X @ W)\n",
    "        y_class = (y_proba >= 0.5).astype(int)\n",
    "        accuracy = (y_class == y).mean()\n",
    "        print(f\"Итерация {i}\")\n",
    "        print(f\"Logloss: {logloss(y, y_proba):.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "0f8017f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальные веса: [-0.09879358 -1.2334072  -1.44572217  5.18904281  5.15859536]\n",
      "Итераций: 5763\n",
      "Оценка точности модели методом скользящего среднего: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Финальные веса:\", W)\n",
    "i_RMSProp = i\n",
    "print(\"Итераций:\", i_RMSProp)\n",
    "accuracy_RMSProp = accuracy\n",
    "print(\"Оценка точности модели методом скользящего среднего:\", accuracy_RMSProp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e73e1",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию этим методом адаптивной оценки моментов (Nesterov–accelerated Adaptive Moment Estimation, Nadam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "70ba6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация 0\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 10\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 20\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 30\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 40\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 50\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 60\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Итерация 70\n",
      "Logloss: 0.0639\n",
      "Accuracy: 0.9800\n",
      "--------------------------------------------------------\n",
      "Остановились на итерации 74\n"
     ]
    }
   ],
   "source": [
    "# Реализуем метод логистической регрессии методом адаптивной оценки моментов\n",
    "\n",
    "eps = 1e-8\n",
    "W = np.zeros(X.shape[1])\n",
    "# Инициализация переменных\n",
    "m = np.zeros_like(W)\n",
    "v = np.zeros_like(W)\n",
    "t = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    t += 1\n",
    "\n",
    "    grad = gr_logloss(X, cur_W, y)\n",
    "    \n",
    "    # Обновляем моменты\n",
    "    m = beta1 * m + (1 - beta1) * grad\n",
    "    v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
    "    \n",
    "    # Корректируем смещения для моментов\n",
    "    m_hat = m / (1 - beta1 ** t)\n",
    "    v_hat = v / (1 - beta2 ** t)\n",
    "    \n",
    "    # Предсказанный момент для Nesterov\n",
    "    m_bar = beta1 * m_hat + (1 - beta1) * grad / (1 - beta1 ** t)\n",
    "    \n",
    "    # Обновляем веса\n",
    "    W_next = cur_W - learning_rate * m_bar / (np.sqrt(v_hat) + eps)\n",
    "    \n",
    "    # Проверка условия остановки\n",
    "    if np.linalg.norm(W - W_next) <= eps:\n",
    "        print(f\"Остановились на итерации {i}\")\n",
    "        break       \n",
    "    \n",
    "    # Обновляем веса для следующей итерации\n",
    "    W = W_next\n",
    "\n",
    "    # Каждые 10 итераций выводим информацию\n",
    "    if i % 10 == 0:\n",
    "        y_proba = sigmoid(X @ W)\n",
    "        y_class = (y_proba >= 0.5).astype(int)\n",
    "        accuracy = (y_class == y).mean()\n",
    "        print(f\"Итерация {i}\")\n",
    "        print(f\"Logloss: {logloss(y, y_proba):.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "a84e77e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальные веса: [-0.0997935  -1.23440719 -1.44672217  5.19004285  5.1595954 ]\n",
      "Итераций: 74\n",
      "Оценка точности модели методом адаптивной оценки моментов: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Финальные веса:\", W)\n",
    "i_Nadam = i\n",
    "print(\"Итераций:\", i_Nadam)\n",
    "accuracy_Nadam = accuracy\n",
    "print(\"Оценка точности модели методом адаптивной оценки моментов:\", accuracy_Nadam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cd131",
   "metadata": {},
   "source": [
    "Сравните значение метрик для реализованных методов оптимизации. Напишите вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "04ae991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Метод': ['Логистическая регрессия', 'Градиентный спуск', 'Метод скользящего среднего', 'Метод Нестерова'],\n",
    "    'Метрика': [score, accuracy_grad, accuracy_RMSProp, accuracy_Nadam],\n",
    "    'Время работы (итераций)': [1, i_grad, i_RMSProp, i_Nadam]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "751d1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Метод  Метрика  Время работы (итераций)\n",
      "0     Логистическая регрессия     0.95                        1\n",
      "1           Градиентный спуск     0.95                     8846\n",
      "2  Метод скользящего среднего     0.98                     5763\n",
      "3             Метод Нестерова     0.98                       74\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684219fe",
   "metadata": {},
   "source": [
    "### Итоги:\n",
    "На выходе мы имеем хорошие показатели метрики оценки качества модели по всем используемым методам. Метод Нестерова показывает самый быстрый расчет по сравнению с Градиентным спуском и Скользящим средним. Наилучшие показатели точности у Метода скользящего среднего и Нестерова. Подводя итог, можно сделать вывод, что скорость и полученная метрика зависят от настроек параметров. В частности, варьируя показателями скорости обучения и количеством итераций можно повысить метрику качества для Градиентного спуска до 0.97 (learning_rate = 0.01, epochs = 100000).\n",
    "\n",
    "PS. Стоит также отметить, что в написанных функциях обучение происходит на всей выборке X (а в модуле LogisticRegression мы используем тренировочную выборку)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
